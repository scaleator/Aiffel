{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68375</th>\n",
       "      <td>Hey, be careful with that!</td>\n",
       "      <td>Hé, faites attention avec ça !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122509</th>\n",
       "      <td>I'm afraid we don't have any left.</td>\n",
       "      <td>J'ai peur que nous n'en ayons plus.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110872</th>\n",
       "      <td>I lived in Sanda City last year.</td>\n",
       "      <td>L'année dernière je vivais à Sanda City.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150764</th>\n",
       "      <td>We've been unable to determine the cause.</td>\n",
       "      <td>Nous avons été incapables d'en déterminer la c...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>Did I hurt you?</td>\n",
       "      <td>Vous ai-je blessé ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              eng  \\\n",
       "68375                  Hey, be careful with that!   \n",
       "122509         I'm afraid we don't have any left.   \n",
       "110872           I lived in Sanda City last year.   \n",
       "150764  We've been unable to determine the cause.   \n",
       "7378                              Did I hurt you?   \n",
       "\n",
       "                                                      fra  \\\n",
       "68375                      Hé, faites attention avec ça !   \n",
       "122509                J'ai peur que nous n'en ayons plus.   \n",
       "110872           L'année dernière je vivais à Sanda City.   \n",
       "150764  Nous avons été incapables d'en déterminer la c...   \n",
       "7378                                  Vous ai-je blessé ?   \n",
       "\n",
       "                                                       cc  \n",
       "68375   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "122509  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
       "110872  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "150764  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "7378    CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23065</th>\n",
       "      <td>Can you believe it?</td>\n",
       "      <td>Arrives-tu à le croire ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32551</th>\n",
       "      <td>Tom works in Boston.</td>\n",
       "      <td>Tom travaille à Boston.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15146</th>\n",
       "      <td>I really mean it.</td>\n",
       "      <td>Je suis sérieuse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17705</th>\n",
       "      <td>You need to stop.</td>\n",
       "      <td>Il faut que vous arrêtiez.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8621</th>\n",
       "      <td>Is French easy?</td>\n",
       "      <td>Le français est-il facile ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eng                          fra\n",
       "23065   Can you believe it?     Arrives-tu à le croire ?\n",
       "32551  Tom works in Boston.      Tom travaille à Boston.\n",
       "15146     I really mean it.            Je suis sérieuse.\n",
       "17705     You need to stop.   Il faut que vous arrêtiez.\n",
       "8621        Is French easy?  Le français est-il facile ?"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 3만3000개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소문자로 변형 및 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      eng                 fra\n",
      "16439  that is fantastic.  c'est fantastique.\n",
      "                        eng                           fra\n",
      "25128  i am still in shock.  je suis encore sous le choc.\n",
      "                       eng                        fra\n",
      "22807  you are very brave.  vous êtes fort courageux.\n",
      "                         eng                     fra\n",
      "31305  now let is celebrate.  maintenant, fêtons ça.\n",
      "                        eng                              fra\n",
      "0                       go                              va  \n",
      "1                       hi                           salut  \n",
      "2                       hi                            salut \n",
      "3                      run                           cours  \n",
      "4                      run                          courez  \n",
      "...                     ...                              ...\n",
      "32995  what was their goal             quel était leur but  \n",
      "32996  what were you doing   qu étais tu en train de faire  \n",
      "32997  what would tom need    de quoi tom aurait il besoin  \n",
      "32998  what would you like                  qu aimerais tu  \n",
      "32999  what would you like                qu aimeriez vous  \n",
      "\n",
      "[33000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "lines['eng'] = lines['eng'].str.lower()\n",
    "lines['fra'] = lines['fra'].str.lower()\n",
    "lines['eng'] = lines['eng'].str.replace('\\'s', ' is') # 's 를 is 로 변경\n",
    "lines['eng'] = lines['eng'].str.replace('\\'re', ' are') # 're --> are\n",
    "lines['eng'] = lines['eng'].str.replace('\\'m', ' am') \n",
    "print(lines.loc[[16439]])\n",
    "print(lines.loc[[25128]])\n",
    "print(lines.loc[[22807]])\n",
    "print(lines.loc[[31305]])\n",
    "                                        \n",
    "lines['eng'] = lines['eng'].str.replace('\\W', ' ') #영어, 프랑스어 특수문자 모두 제거\n",
    "lines['fra'] = lines['fra'].str.replace('\\W', ' ') \n",
    "#lines['eng'] = lines['eng'].str[:-1] + ' ' +lines['eng'].str[-1:]\n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22327</th>\n",
       "      <td>why are you alone</td>\n",
       "      <td>\\t pourquoi êtes vous seules   \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>advance two steps</td>\n",
       "      <td>\\t avance de deux pas  \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30082</th>\n",
       "      <td>i said it as a joke</td>\n",
       "      <td>\\t je l ai dit comme une blague  \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>no one can say</td>\n",
       "      <td>\\t personne ne peut le dire  \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25797</th>\n",
       "      <td>now is your chance</td>\n",
       "      <td>\\t c est l occasion ou jamais  \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eng                                  fra\n",
       "22327    why are you alone     \\t pourquoi êtes vous seules   \\n\n",
       "18000    advance two steps             \\t avance de deux pas  \\n\n",
       "30082  i said it as a joke   \\t je l ai dit comme une blague  \\n\n",
       "8934        no one can say       \\t personne ne peut le dire  \\n\n",
       "25797   now is your chance     \\t c est l occasion ou jamais  \\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 5, 1], [9, 3, 1], [9, 3, 1]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level=True) # 문자 단위로 Tokenizer를 생성합니다.\n",
    "eng_tokenizer.fit_on_texts(lines.eng) # 33000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 1, 18, 4, 1, 1, 1, 11],\n",
       " [10, 1, 3, 4, 13, 8, 5, 1, 1, 1, 11],\n",
       " [10, 1, 3, 4, 13, 8, 5, 1, 1, 11]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=True)   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # 33000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 39\n",
      "프랑스어 단어장의 크기 : 53\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 22\n",
      "프랑스어 시퀀스의 최대 길이 61\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 39\n",
      "프랑스어 단어장의 크기 : 53\n",
      "영어 시퀀스의 최대 길이 22\n",
      "프랑스어 시퀀스의 최대 길이 61\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 1, 18, 4, 1, 1, 1], [10, 1, 3, 4, 13, 8, 5, 1, 1, 1], [10, 1, 3, 4, 13, 8, 5, 1, 1]]\n",
      "[[1, 18, 4, 1, 1, 1, 11], [1, 3, 4, 13, 8, 5, 1, 1, 1, 11], [1, 3, 4, 13, 8, 5, 1, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 22)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 61)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 61)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  5  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 22, 39)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 61, 53)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 61, 53)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 22, 39)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 61, 53)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 61, 53)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print('⏳')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking\n",
    "\n",
    "#인코더에서 사용할 임베딩 층\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(33000, 16)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units = 256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "print(encoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#디코더에서 사용할 임베딩 층\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb =  Embedding(33000, 16)(decoder_inputs)\n",
    "decoder_lstm = LSTM(units = 256, return_state=True)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lstm_8/PartitionedCall:0\", shape=(None, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#입력 텐서 생성.\n",
    "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
    "#hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "#디코더로 전달할 hidden state, cell state를 리턴. encoder_outputs은 여기서는 불필요.\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "#hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장.\n",
    "encoder_states = [state_h, state_c]\n",
    "print(encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 텐서 생성.\n",
    "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
    "#hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "#decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 16s 662ms/step - loss: 1.8213 - val_loss: 1.5508\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 15s 643ms/step - loss: 1.2738 - val_loss: 1.3183\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 15s 640ms/step - loss: 1.1704 - val_loss: 1.2871\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 15s 628ms/step - loss: 1.0948 - val_loss: 1.2753\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 15s 630ms/step - loss: 1.0393 - val_loss: 1.1610\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 15s 629ms/step - loss: 0.9778 - val_loss: 1.0992\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 15s 630ms/step - loss: 0.9139 - val_loss: 1.0445\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 15s 631ms/step - loss: 0.8624 - val_loss: 0.9881\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 15s 630ms/step - loss: 0.8187 - val_loss: 0.9429\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 15s 632ms/step - loss: 0.7833 - val_loss: 0.9203\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 15s 631ms/step - loss: 0.7538 - val_loss: 0.8772\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 15s 632ms/step - loss: 0.7254 - val_loss: 0.8512\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 15s 633ms/step - loss: 0.7018 - val_loss: 0.8254\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 15s 634ms/step - loss: 0.6838 - val_loss: 0.8297\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 15s 634ms/step - loss: 0.6660 - val_loss: 0.7971\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 15s 633ms/step - loss: 0.6528 - val_loss: 0.8057\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 15s 633ms/step - loss: 0.6486 - val_loss: 0.7744\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 15s 633ms/step - loss: 0.6360 - val_loss: 0.7640\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 15s 632ms/step - loss: 0.6212 - val_loss: 0.7519\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 15s 631ms/step - loss: 0.6098 - val_loss: 0.7297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f323d02dd90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.fit([encoder_input_train, decoder_input_train], decoder_target_train,\n",
    "          batch_size=1024,\n",
    "          epochs=20,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, None, 39)]        0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                [(None, 256), (None, 256) 303104    \n",
      "=================================================================\n",
      "Total params: 303,104\n",
      "Trainable params: 303,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, None, 53)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, None, 256),  317440      input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 53)     13621       lstm_9[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 331,061\n",
      "Trainable params: 331,061\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "    target_seq[0, 0, fra2idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: run \n",
      "정답 문장:  cours   \n",
      "번역기가 번역한 문장:  ne sous pas pas  \n",
      "-----------------------------------\n",
      "입력 문장: i left \n",
      "정답 문장:  je suis partie  \n",
      "번역기가 번역한 문장:  je ne suis pas de mon  \n",
      "-----------------------------------\n",
      "입력 문장: call us \n",
      "정답 문장:  appelez nous   \n",
      "번역기가 번역한 문장:  nous avons pas  \n",
      "-----------------------------------\n",
      "입력 문장: how nice \n",
      "정답 문장:  comme c est gentil   \n",
      "번역기가 번역한 문장:  tom est pas de mon  \n",
      "-----------------------------------\n",
      "입력 문장: turn left \n",
      "정답 문장:  tourne à gauche  \n",
      "번역기가 번역한 문장:  qui le t a pas  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구글 번역기로 확인한 결과 번역이 정확하다는것을 알수 있었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
